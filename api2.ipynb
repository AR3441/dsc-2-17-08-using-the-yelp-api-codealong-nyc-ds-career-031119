{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Data From Twitter - Lab \n",
    "\n",
    "## Introduction\n",
    "In this lab, we shall use our Twitter developer account and the keys we generated in the previous lesson to make some API calls to twitter. We shall look at a number of ways of accessing twitter data which may suit different use cases for twitter API calling. We shall also get an introduction to the `tweepy` Python library to help us with tweet mining and parsing. \n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Successfully request tweet data from the Twitter API using the Tweepy library\n",
    "* Understand and explain the concept of semi-structured data\n",
    "* Parse tweet data and perform basic twitter analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tweepy`\n",
    "\n",
    "Tweepy is open-source library, hosted on GitHub and enables Python to communicate with Twitter platform and use its API. Visit [HERE](https://pythonhosted.org/tweepy/index.html) for TWeepy's official documentation. Installing tweepy is easy, it can be pip installed as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and pip install tweepy if you havent done so already\n",
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now simply import import tweepy in the python working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tweepy\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are now good to move on with setting up tweepy with our user and access tokens. \n",
    "\n",
    "### Using tweepy\n",
    "Tweepy supports accessing Twitter through OAuth. Twitter has stopped accepting Basic Authentication so OAuth is now the only way to use the Twitter API. In order create the API object, however, we must first authenticate ourselves with our developer information.\n",
    "* Enter your credentials into access_token, access_token_secret, consumer_key, and consumer_secret below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credential variables with appropriate values\n",
    "consumer_key = \"Bqi4VGVT34L55ePRiZF80QlGX\"\n",
    "consumer_secret = \"PuxXMs4z04MWIgc2AnDIuLS7gow2P3DVu0B0pjC5vBehpb5jS6\"\n",
    "access_token = \"1019612699288915970-Zs9genL06wJmu8dCdwnCIJZt9tFind\"\n",
    "access_token_secret = \"6fzYuRBpyR51h7ByTyYdSattJlM3LBSNrEiUpTJQKW60z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Authentication Object\n",
    "\n",
    "Our next step would be to create tweepy  OAuthHandler instance with our consumer key and secret and set access token and secret using `tweepy.set_access_token`. We can then create an API object with this information.\n",
    "\n",
    "We shall set it up as shown below:\n",
    "\n",
    "```python\n",
    "# Create the tweepy authentication object with consumer key and secret\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste above code here with your credentials to create the Oauth Handler Instance and API object\n",
    "\n",
    "# Create the tweepy authentication object with consumer key and secret\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start using the Twitter API through `api` object .\n",
    "\n",
    "NOTE: If you have a web application and are using a callback URL that needs to be supplied dynamically, you would pass it in like shown below:\n",
    "```python\n",
    "auth = tweepy.OAuthHandler(consumer_token, consumer_secret, callback_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The API Object - `home_timeline()` method\n",
    "A detailed indsight into Tweepy's API object with supported methods to post, retrieve and select tweets can be found at [Tweepy's API Dcoumentation](https://pythonhosted.org/tweepy/api.html#api-reference). \n",
    "\n",
    "We can directly collect tweets from our home timeline by applying the method `api.home_timeline()`, which collects 20 most recent tweets by default (including retweeted tweets). To adjust the desired number of tweets (take 100 tweets for example),  we can pass in a parameter value as (count = 100).\n",
    "\n",
    "By default we get first 140 characters of a tweet. We can, however, optionally pass in an extra argument `tweet_mode='extended'` to get the full length of the tweet. This might be useful if you are interested in analyzing the full text of tweets rather than geographical locations, and hashtags etc. only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the API object to get tweets from your timeline ,collect 10 tweets\n",
    "# Store the tweets it in a variable called my_timeline_tweets\n",
    "\n",
    "my_timeline_tweets = api.home_timeline(count=10, tweet_mode='extended')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet JSON\n",
    "\n",
    "All Twitter APIs that return Tweets provide that data encoded using JavaScript Object Notation (JSON). Each Tweet has an **author**, a **message**, a **unique ID**, a **timestamp** of when it was posted, and sometimes **geo metadata** shared by the user. Each User has a Twitter **name**, an **ID**, a **number of followers**, and most often an account **bio**.\n",
    "\n",
    "With each Tweet we also get **\"entity\"** objects, which are arrays of common Tweet contents such as **hashtags**, **mentions**, **media**, and **links**. If there are links, the JSON payload can also provide metadata such as the fully unwound URL and the webpageâ€™s title and description.\n",
    "\n",
    "Here is what a Tweet JSON structure looks like:\n",
    "```pythpn\n",
    "{\n",
    "  \"created_at\": \"Thu Apr 06 15:24:15 +0000 2017\",\n",
    "  \"id_str\": \"850006245121695744\",\n",
    "  \"text\": \"1\\/ Today we\\u2019re sharing our vision for the future of the Twitter API platform!\\nhttps:\\/\\/t.co\\/XweGngmxlP\",\n",
    "  \"user\": {\n",
    "    \"id\": 2244994945,\n",
    "    \"name\": \"Twitter Dev\",\n",
    "    \"screen_name\": \"TwitterDev\",\n",
    "    \"location\": \"Internet\",\n",
    "    \"url\": \"https:\\/\\/dev.twitter.com\\/\",\n",
    "    \"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \\u2328\\ufe0f #TapIntoTwitter\"\n",
    "  },\n",
    "  \"place\": {   \n",
    "  },\n",
    "  \"entities\": {\n",
    "    \"hashtags\": [      \n",
    "    ],\n",
    "    \"urls\": [\n",
    "      {\n",
    "        \"url\": \"https:\\/\\/t.co\\/XweGngmxlP\",\n",
    "        \"unwound\": {\n",
    "          \"url\": \"https:\\/\\/cards.twitter.com\\/cards\\/18ce53wgo4h\\/3xo1c\",\n",
    "          \"title\": \"Building the Future of the Twitter API Platform\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"user_mentions\": [     \n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate through collected tweets in `my_timeline_tweets` to access any of the properties of each tweet. Let's print the name of user with `.user.name` propoerty and content of the each tweet using the `.text` property. (or `.full_text` in case of using `tweet_mode='extended'` full text beyond 140 character limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Data&Science ðŸŽƒ\n",
      "RT @kylegriffin1: Lyft is partnering with Voto Latino to take voters to polls in Dodge City, Kansas after the city's only polling site wasâ€¦\n",
      "----------------------------------------------------------------------------\n",
      "Data Science Central\n",
      "Wrongness of the Nogs https://t.co/UejGJei2bx\n",
      "----------------------------------------------------------------------------\n",
      "Dr. Data&Science ðŸŽƒ\n",
      "RT @JustJen2015: @dataandpolitics https://t.co/M2mpRXfLB5\n",
      "----------------------------------------------------------------------------\n",
      "Data Science Central\n",
      "Most popular data science keywords on DSC https://t.co/B10wjC7cDq\n",
      "----------------------------------------------------------------------------\n",
      "Data Science Central\n",
      "Data Science and Machine Learning: Great List of Resources https://t.co/qofGIQlPMz\n",
      "----------------------------------------------------------------------------\n",
      "Data Science Central\n",
      "Using Confusion Matrices to Quantify the Cost of Being Wrong https://t.co/Ff1mnXFi46\n",
      "----------------------------------------------------------------------------\n",
      "Dr. Data&Science ðŸŽƒ\n",
      "RT @LaurenRPfeifer: @dataandpolitics Crazy eyes over here wants some pets. https://t.co/xYBT64ykV8\n",
      "----------------------------------------------------------------------------\n",
      "Dr. Data&Science ðŸŽƒ\n",
      "RT @stlbf: @darth, @dataandpolitics, @stlkerri This feels sooooo familiar! https://t.co/cWn2szb1EH\n",
      "----------------------------------------------------------------------------\n",
      "Data Science & Engineering\n",
      "A curated list of awesome #machinelearning frameworks, libraries and software (by language).Â  https://t.co/0pQJ235Syb https://t.co/XCPT0s61po\n",
      "----------------------------------------------------------------------------\n",
      "Data Science Central\n",
      "New Marketing Insight from Unsupervised Bayesian Belief Networks https://t.co/Ew04j5MPWP\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# foreach through all tweets pulled\n",
    "for tweet in my_timeline_tweets:\n",
    "   # printing the name and full text stored inside the tweet object\n",
    "    print (tweet.user.name)\n",
    "    print (tweet.full_text)\n",
    "    print ('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, weâ€™ll simply pull the latest twenty tweets from a user of our choice.\n",
    "\n",
    "First, weâ€™ll examine the Tweepy documentation to see if a function like that exists. With a bit of research, we find that the user_timeline() function is what weâ€™re looking for.\n",
    "\n",
    "We can see that the user_timeline() function has some useful parameters we can use, specifically id (the ID of the user) and count (the amount of tweets we want to pull). Note that we can only pull a limited number of tweets per query due to Twitterâ€™s rate limits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "my_list_of_dicts = []\n",
    "for each_json_tweet in my_timeline_tweets:\n",
    "    my_list_of_dicts.append(each_json_tweet._json)\n",
    "\n",
    "with open('test.txt', 'w') as file:\n",
    "    file.write(json.dumps(my_list_of_dicts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_demo_list = []\n",
    "with open('test.txt', encoding='utf-8') as json_file:  \n",
    "    all_data = json.load(json_file)\n",
    "    for each_dictionary in all_data:\n",
    "        tweet_id = each_dictionary['id']\n",
    "        text = each_dictionary['full_text']\n",
    "        favorite_count = each_dictionary['favorite_count']\n",
    "        retweet_count = each_dictionary['retweet_count']\n",
    "        created_at = each_dictionary['created_at']\n",
    "        my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                             'text': str(text),\n",
    "                             'favorite_count': int(favorite_count),\n",
    "                             'retweet_count': int(retweet_count),\n",
    "                             'created_at': created_at,\n",
    "                            })\n",
    "        #print(my_demo_list)\n",
    "        tweet_json = pd.DataFrame(my_demo_list, columns = \n",
    "                                  ['tweet_id', 'text', \n",
    "                                   'favorite_count', 'retweet_count', \n",
    "                                   'created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054544301940600832</td>\n",
       "      <td>RT @kylegriffin1: Lyft is partnering with Voto...</td>\n",
       "      <td>0</td>\n",
       "      <td>5625</td>\n",
       "      <td>Tue Oct 23 01:25:28 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1054529839309430784</td>\n",
       "      <td>Wrongness of the Nogs https://t.co/UejGJei2bx</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue Oct 23 00:28:00 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1054525325697146880</td>\n",
       "      <td>RT @JustJen2015: @dataandpolitics https://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue Oct 23 00:10:04 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1054514738758144000</td>\n",
       "      <td>Most popular data science keywords on DSC http...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Mon Oct 22 23:28:00 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1054507965242396672</td>\n",
       "      <td>Data Science and Machine Learning: Great List ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon Oct 22 23:01:05 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1054497124434485248</td>\n",
       "      <td>Using Confusion Matrices to Quantify the Cost ...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon Oct 22 22:18:00 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1054488563868327937</td>\n",
       "      <td>RT @LaurenRPfeifer: @dataandpolitics Crazy eye...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Oct 22 21:43:59 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1054488304136019970</td>\n",
       "      <td>RT @stlbf: @darth, @dataandpolitics, @stlkerri...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Oct 22 21:42:57 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1054482998672982016</td>\n",
       "      <td>A curated list of awesome #machinelearning fra...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Oct 22 21:21:52 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1054482780959191040</td>\n",
       "      <td>New Marketing Insight from Unsupervised Bayesi...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon Oct 22 21:21:00 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1054544301940600832  RT @kylegriffin1: Lyft is partnering with Voto...   \n",
       "1  1054529839309430784      Wrongness of the Nogs https://t.co/UejGJei2bx   \n",
       "2  1054525325697146880  RT @JustJen2015: @dataandpolitics https://t.co...   \n",
       "3  1054514738758144000  Most popular data science keywords on DSC http...   \n",
       "4  1054507965242396672  Data Science and Machine Learning: Great List ...   \n",
       "5  1054497124434485248  Using Confusion Matrices to Quantify the Cost ...   \n",
       "6  1054488563868327937  RT @LaurenRPfeifer: @dataandpolitics Crazy eye...   \n",
       "7  1054488304136019970  RT @stlbf: @darth, @dataandpolitics, @stlkerri...   \n",
       "8  1054482998672982016  A curated list of awesome #machinelearning fra...   \n",
       "9  1054482780959191040  New Marketing Insight from Unsupervised Bayesi...   \n",
       "\n",
       "   favorite_count  retweet_count                      created_at  \n",
       "0               0           5625  Tue Oct 23 01:25:28 +0000 2018  \n",
       "1               0              1  Tue Oct 23 00:28:00 +0000 2018  \n",
       "2               0              1  Tue Oct 23 00:10:04 +0000 2018  \n",
       "3               3              2  Mon Oct 22 23:28:00 +0000 2018  \n",
       "4               8              3  Mon Oct 22 23:01:05 +0000 2018  \n",
       "5               5              3  Mon Oct 22 22:18:00 +0000 2018  \n",
       "6               0              1  Mon Oct 22 21:43:59 +0000 2018  \n",
       "7               0              1  Mon Oct 22 21:42:57 +0000 2018  \n",
       "8               5              1  Mon Oct 22 21:21:52 +0000 2018  \n",
       "9               4              4  Mon Oct 22 21:21:00 +0000 2018  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To collect tweets from a particular account (take @NatGeo for example), use the method our_api.user_timeline(screen_name = 'NatGeo', count = 100).\n",
    "\n",
    "\n",
    "Letâ€™s try pulling the latest twenty tweets from twitter account @NyTimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Stay-at-home moms in Nebraska who have a limited grocery budget to live off of â€” no politician can understand thatâ€¦ https://t.co/DDiuNWChSd\n",
      "Happy Monday! In case you need this today... https://t.co/XBEPHZwA2Q\n",
      "In his morning tweets, President Trump attempted to stoke fear about a caravan of migrants and blamed Democrats forâ€¦ https://t.co/OPDascYtpJ\n",
      "RT @nytpolitics: Itâ€™s Monday, President Trump and Ted Cruz are friends again, and there are 15 days until the midterm elections https://t.câ€¦\n",
      "\"The hurt that's been caused to people of faith by people of faith, that's just really hard to come to terms with.\"â€¦ https://t.co/1mpo9GvzIA\n"
     ]
    }
   ],
   "source": [
    "# The Twitter user who we want to get tweets from\n",
    "name = \"nytimes\"\n",
    "# Number of tweets to pull\n",
    "tweetCount = 5\n",
    "# Calling the user_timeline function with our parameters\n",
    "results = api.user_timeline(id=name, count=tweetCount)\n",
    "# foreach through all tweets pulled\n",
    "for tweet in results:\n",
    "   # printing the text stored inside the tweet object\n",
    "   print (tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3: Finding Tweets Using a Keyword\n",
    "Letâ€™s do one last example: Getting the most recent tweets that contain a keyword. This can be extremely useful if you want to monitor specifically mentioned topics in the Twitter world, or even to see how your business is getting mentioned. Letâ€™s say we want to see how Twitterâ€™s been mentioning Toptal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suem1951 Tweeted: RT @DAaronovitch: Another morning another ERGer peddling Brexit fantasies on the radio. This time Mark Francois MP describing a delegationâ€¦\n",
      "timbercouk Tweeted: RT @WalesOnline: How Welsh ports plan to tackle Brexit fears with a plan to boost the economy \n",
      "\n",
      "https://t.co/O3WxOdBtZK https://t.co/QD5haEâ€¦\n",
      "ophidianpilot Tweeted: Trainspotting Creator: Soros-Funded Anti-Brexit Campaign Is 'Smug, Patronising, Pish' https://t.co/F9ja3rWXQD via @BreitbartLondon\n",
      "marthafisherlit Tweeted: @guardian the ghost of #brexit - finally captured on a photo!\n",
      "ChrisDa1917 Tweeted: RT @labourleave: Superb essay!\n",
      "\n",
      "Long read: how EU membership undermines the left https://t.co/RX0HvZtnZj #Brexit\n",
      "D1222221 Tweeted: RT @LeaveMnsLeave: .@Nigel_Farage: Theresa May must stand up to the EU's creepy efforts to impose itself on Brexit Britain https://t.co/I8Eâ€¦\n",
      "sureduck Tweeted: RT @MarcusJBall: Our crowdfunded private prosecution case against @BorisJohnson  has now achieved financial backing from almost 7000 peopleâ€¦\n",
      "PaulStollery Tweeted: The second half of this tweet reads an awful lot like 'Labour aren't backing Brexit but vote for us anyway' https://t.co/YOyDx1VnGD\n",
      "Mobile_Homme Tweeted: RT @Econs4FreeTrade: Theresa Mayâ€™s plans for post-Brexit trade with the European Union will face further backlash today when a group of Conâ€¦\n",
      "JillAshleyJone1 Tweeted: RT @PimlicoPlumbers: #Brexit Is A Neverending Nightmare And 80% Of Businesses Agree https://t.co/LiEer8hYAd\n",
      "JuliaJones35 Tweeted: RT @TelBabe: As Labour's Starmer pockets his money from this anti-Brexit firm, he gets excited about The People's March Against Democracy iâ€¦\n",
      "FAO_Scotbot Tweeted: RT @thomasbrake: Considering the mess the Government has made of #Brexit the fact 95% of the shambles is complete is unlikely to bring confâ€¦\n",
      "UKFreeNews Tweeted: Thanks to any and every one for prayers. Keep up the Good work :). xâ€¦ https://t.co/TWzHDaww6n\n",
      "Dclell Tweeted: RT @Andrew_Adonis: Farage told me on LBC that Cameronâ€™s document sent to every voter before the 2016 referendum said â€˜leaveâ€™ meant leavingâ€¦\n",
      "JBlackmore_FBPE Tweeted: RT @barn38: @JSHeappey Cool heads indeed needed James.  So with that in mind I do hope you will vote accordingly to stop a no deal Brexit.â€¦\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The search term you want to find\n",
    "query = \"brexit\"\n",
    "# Language code (follows ISO 639-1 standards)\n",
    "language = \"en\"\n",
    "# Calling the user_timeline function with our parameters\n",
    "results = api.search(q=query, lang=language)\n",
    "# foreach through all tweets pulled\n",
    "c = 0\n",
    "for tweet in results:\n",
    "   # printing the text stored inside the tweet object\n",
    "    print (tweet.user.screen_name,\"Tweeted:\",tweet.text)\n",
    "    c=c+1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
